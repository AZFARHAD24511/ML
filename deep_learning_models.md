# پروژه پیش‌بینی NetIncomeLoss

در این پروژه ابتدا از **الگوریتم جنگل تصادفی (Random Forest)** برای پیش‌بینی `NetIncomeLoss` استفاده کردیم و به نتایج بسیار خوبی رسیدیم:

- **ویژگی اصلی**: `lag_5` (مقدار درآمد خالص در ۵ دوره‌ی قبلی)  
- **نتیجه**:  
  - **R² ≈ 0.92**  
  - **MAE و RMSE** در مقیاس میلیارد  
  - زمان آموزش و ارزیابی بسیار سریع  

با این موفقیت، فرض کردیم که مدل‌های سری‌زمانی قوی‌تر مانند **LSTM** بتوانند از وابستگی‌های طولانی‌مدت استفاده کرده و نتایج حتی بهتری بدهند. بنابراین:

1. **ادغام lagهای متعدد** (`lag_1` تا `lag_5`)  
2. **اضافه کردن ویژگی‌های rolling** (`rolling_mean_4`, `rolling_std_4`)  
3. **مقیاس‌سازی y با log1p و PowerTransformer**  
4. **افزایش عمق شبکه** (۲ لایه LSTM با 64 و 32 واحد)  
5. **استفاده از Dropout و EarlyStopping** برای جلوگیری از overfitting  

با وجود پیاده‌سازی کامل و انجام آزمون‌های متعدد:

- **Training/Validation Loss** روی مقیاس لگاریتم، بهبود اندکی نشان داد  
- **R²** روی مقیاس اصلی: **≈ 0.08**  
- **RMSE**: تقریباً 9.1 میلیارد  
- مدل LSTM نتوانست وابستگی‌های مالی خاص این داده را به‌خوبی یاد بگیرد و عملاً **underfitting** داشت.

---

## نتیجه‌گیری

- **جنگل تصادفی** با ویژگی‌های ساده‌ی lag توانست **بیش از 90%** واریانس را در پیش‌بینی `NetIncomeLoss` توضیح دهد.  
- **LSTM** علیرغم پیچیدگی و پتانسیل تئوری، برای این نوع داده‌های فصلی و مالی کوتاه‌مدت عملکرد ضعیف‌تری داشت.  
- برخی ساختارهای **پایدار و پراکته‌شده** مثل Random Forest برای این دسته داده‌ها مناسب‌تر هستند و به‌خصوص وقتی که سیگنال از طریق lagهای گذشته به‌خوبی قابل استخراج است.

> **پیشنهاد نهایی**:  
> برای داده‌هایی با مقیاس بزرگ، پراکندگی شدید و وابستگی‌های فصلی کوتاه‌مدت، نگه‌داشتن الگوریتم‌های **درختی** (Random Forest / XGBoost) به‌عنوان baseline و گزینه اصلی پیش‌بینی، ساده و کارا است.  
> شبکه‌های LSTM و مدل‌های سری‌زمانی پیشرفته را می‌توان برای مسائل دیگر با ساختار بلندمدت و داده‌های پیوسته در نظر گرفت.
